% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/poly_link_daily.R
\name{poly_link_daily}
\alias{poly_link_daily}
\title{Link Spatial Data with Copernicus Earth Observation Daily Indicators}
\usage{
poly_link_daily(
  indicator,
  data,
  date_var,
  time_span = 0,
  time_lag = 0,
  baseline = FALSE,
  order = "ymd",
  path = "./data/raw",
  catalogue = "derived-era5-land-daily-statistics",
  statistic = "daily_mean",
  time_zone = "utc+00:00",
  keep_raw = FALSE,
  parallel = FALSE,
  chunk_size = 50
)
}
\arguments{
\item{indicator}{Character string specifying the indicator to download (e.g., "2m_temperature").
Allowed indicators differ by catalogue. See the \strong{Details} section for available indicators.}

\item{data}{An \code{sf} object containing the spatial data (polygons or points).}

\item{date_var}{Character string specifying the name of the date variable in \code{data}.}

\item{time_span}{Integer specifying the time span in days for averaging the climate indicator values prior to linking
with the spatial data (default is \code{0}).}

\item{time_lag}{Integer specifying the time lag in days to shift the \code{date_var} backward (default is \code{0}).}

\item{baseline}{Either \code{FALSE} (default) or a character vector of length 2 specifying the baseline
period in years. For example, \code{baseline = c("1980", "2010")} uses the years 1980 to 2010 as the baseline.
If \code{FALSE}, no baseline calculation is performed.}

\item{order}{Character string specifying the date format for parsing \code{date_var} (default is \code{"ymd"}).}

\item{path}{Character string specifying the directory path where data will be downloaded and/or stored
(default is \code{"./data/raw"}).}

\item{catalogue}{Character string specifying which ERA5 catalogue to use.
Options are \code{"derived-era5-land-daily-statistics"} (default) or \code{"derived-era5-single-levels-daily-statistics"}.}

\item{statistic}{Character string specifying the type of daily statistic to download.
Options are \code{"daily_mean"} (default), \code{"daily_maximum"}, and \code{"daily_minimum"}.}

\item{time_zone}{Character string specifying the time zone to use (default is \code{"utc+00:00"}).}

\item{keep_raw}{Logical value indicating whether to keep the downloaded raw \code{.grib} files.
If \code{FALSE}, the files are deleted after processing (default is \code{FALSE}).}

\item{parallel}{Logical indicating whether to use parallel processing with chunking.
Default is \code{FALSE} (i.e. sequential execution).}

\item{chunk_size}{Integer specifying the number of observations per chunk when parallelizing.
Default is \code{50}.}
}
\value{
An \code{sf} object with the original spatial data and appended climate indicator values. If a baseline
period is specified, additional columns for baseline values and deviations are included.
}
\description{
Downloads and processes Copernicus Earth observation data (ERA5) based on
spatial and daily temporal parameters, and extracts the relevant daily
climate indicator values for the provided spatial dataset. The function
constructs daily time sequences based on the provided date variable and time
adjustments, downloads the corresponding daily statistics (mean, maximum,
or minimum), and links these values to the spatial features. If a baseline
period is specified, baseline daily statistics are downloaded for the
corresponding days across the baseline years and compared with the focal
values.
}
\details{
This function interacts with the Copernicus Climate Data Store (CDS) API to download ERA5 daily reanalysis data for a specified
climate indicator and time period based on daily temporal resolution. It processes the spatial data to determine the geographic
extent and constructs daily time sequences based on the provided \code{date_var}, \code{time_span}, and \code{time_lag}. The function downloads
the corresponding daily statistics (e.g. daily mean, maximum, or minimum) and extracts these values for each spatial feature.

If a baseline period is provided (e.g. \code{baseline = c("1980", "2010")}), the function downloads baseline daily statistics for the
specified period and calculates the average value for the same day (e.g., 3rd February, 15th March, etc.) across the baseline years.
It then computes the deviation between the focal and baseline values.

\strong{Note:} Users must have a CDS account and have their API key configured for \code{ecmwfr}.

\strong{Parallel Processing:}
This function can use parallel processing with chunking via
\code{future.apply::future_lapply} when \code{parallel = TRUE}. If \code{parallel = FALSE},
the function runs sequentially. When \code{parallel = TRUE}, set your parallel
plan (for example, using \code{future::plan(multisession, workers = 6)})
before calling this function. If no plan is set before but \code{parallel = TRUE},
the function will run sequentially through the chunks, which will most
likely increase duration.
}
\examples{
\dontrun{
library(sf)
library(dplyr)

# Example 1: Sequential mode with no baseline and time_span = 0
result1 <- poly_link_daily(
  indicator = "2m_temperature",
  data = my_data,
  date_var = "date_column",
  time_span = 0,
  time_lag = 0,
  baseline = FALSE,
  order = "ymd",
  path = "./data/raw",
  catalogue = "derived-era5-land-daily-statistics",
  statistic = "daily_mean",
  time_zone = "utc+00:00",
  keep_raw = FALSE
)

# Example 2: Sequential mode with a baseline period specified
result2 <- poly_link_daily(
  indicator = "2m_temperature",
  data = my_data,
  date_var = "date_column",
  time_span = 0,
  time_lag = 0,
  baseline = c("1980", "2010"),
  order = "ymd",
  path = "./data/raw",
  catalogue = "derived-era5-land-daily-statistics",
  statistic = "daily_maximum",
  time_zone = "utc+00:00",
  keep_raw = TRUE
)

# Example 3: Parallel processing with chunking and baseline specified
library(future)
plan(multisession, workers = 6)

result3 <- poly_link_daily(
  indicator = "2m_temperature",
  data = my_data,
  date_var = "date_column",
  time_span = 0,
  time_lag = 0,
  baseline = c("1980", "2010"),
  order = "ymd",
  path = "./data/raw",
  catalogue = "derived-era5-land-daily-statistics",
  statistic = "daily_minimum",
  time_zone = "utc+00:00",
  keep_raw = TRUE,
  parallel = TRUE,
  chunk_size = 50
)

# View the results:
head(result1)
head(result2)
head(result3)
}

}
