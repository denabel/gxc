% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/link_monthly.R
\name{link_monthly}
\alias{link_monthly}
\alias{link_monthly.sf}
\alias{link_monthly.SpatRaster}
\alias{link_monthly.stars}
\alias{link_monthly.SpatVector}
\alias{link_monthly.Spatial}
\title{Link with ERA5 monthly indicators}
\usage{
link_monthly(
  .data,
  indicator,
  ...,
  cache = TRUE,
  path = NULL,
  parallel = FALSE,
  chunk_size = 50,
  verbose = TRUE
)

\method{link_monthly}{sf}(
  .data,
  indicator,
  date_var = "date",
  time_span = 0,
  time_lag = 0,
  buffer = 0,
  baseline = FALSE,
  catalogue = "reanalysis-era5-land-monthly-means",
  by_hour = FALSE,
  cache = TRUE,
  path = NULL,
  parallel = FALSE,
  chunk_size = 50,
  verbose = TRUE
)

\method{link_monthly}{SpatRaster}(
  .data,
  indicator,
  time_span = 0,
  time_lag = 0,
  baseline = FALSE,
  method = "bilinear",
  catalogue = "reanalysis-era5-land-monthly-means",
  by_hour = FALSE,
  cache = TRUE,
  path = NULL,
  parallel = FALSE,
  chunk_size = 50,
  verbose = TRUE
)

\method{link_monthly}{stars}(.data, indicator, ...)

\method{link_monthly}{SpatVector}(.data, indicator, ...)

\method{link_monthly}{Spatial}(.data, indicator, ...)
}
\arguments{
\item{.data}{An \code{sf} object containing the spatial data (polygons or points).}

\item{indicator}{Character string specifying the indicator to download
(e.g., \code{"2m_temperature"}). Allowed indicators differ by catalogue. See
the \strong{Details} section for available indicators.}

\item{...}{Arguments passed to methods. If \code{.data} is a stars object,
arguments are passed to \code{link_daily.SpatRaster}, otherwise to
\code{link_daily.sf}.}

\item{cache}{Logical value indicating whether to keep the downloaded
files and restore them when downloading the same file again.
Enabling caching can speed up functions calls significantly when working
with the same files repeatedly. See the \strong{Caching} section for details. If
\code{FALSE}, removes the raw files after processing.}

\item{path}{Character string specifying the directory path where data will
be downloaded and cached. If \code{NULL}, the directory depends on whether
caching is enabled. If \code{cache = FALSE}, files are stored in a temporary
directory (\code{\link{tempdir}}), otherwise they are stored in the user
directory (\code{\link{R_user_dir}}). Defaults to \code{NULL}.}

\item{parallel}{Logical indicating whether to use parallel processing with
chunking. See section \strong{Parallel processing} for details. Default is
\code{FALSE} (i.e., sequential execution).}

\item{chunk_size}{Integer specifying the number of observations per chunk
when parallelizing. This is the number of rows that is processed
simultaneously during parallel processing. Setting this to something lower
than \code{nrow(.data)} increases the total number of parallel processes.
Default is \code{50}.}

\item{date_var}{Character string specifying the name of the date variable in \code{data}.}

\item{time_span}{Integer specifying the time span in days for averaging the
climate indicator values prior to linking with the spatial data (default
is \code{0}).}

\item{time_lag}{Integer specifying the time lag in days to shift the
\code{date_var} backward (default is \code{0}).}

\item{buffer}{Numeric value specifying the buffer radius (in kilometers) to
be applied around each geometry. The default is \code{0}, corresponding to a
direct cell match; values greater than 0 generate a spatial buffer
around each point for aggregated extraction.}

\item{baseline}{Either \code{FALSE} (default) or a character vector of length 2
specifying the baseline period in years. For example,
\code{baseline = c("1980", "2010")} uses the years 1980 to 2010 as the baseline.
If \code{FALSE}, no baseline calculation is performed.}

\item{catalogue}{Character string specifying which ERA5 catalogue to use.
Options are \code{"reanalysis-era5-land-monthly-means"}
or \code{"reanalysis-era5-single-levels-monthly-means"}. The first provides
higher spatial resolution at 0.1x0.1 degrees but is only available from
1950 onwards. If you need data before 1950 or if you are working with large
spatial extents where finer resolution is not required, you can switch to
the latter.}

\item{by_hour}{Logical or character. If \code{FALSE} (default), the monthly
averaged values are derived from the entire day
(\code{"monthly_averaged_reanalysis"}). If a character string specifying an
hour (e.g., \code{"03:00"}), then the dataset
\code{"monthly_averaged_reanalysis_by_hour_of_day"} is used, and only values
from that hour of the day are included.}
}
\value{
An object of the input class (i.e. if \code{.data} is an sf dataframe,
the function returns an sf dataframe) with the original data and appended
climate indicator values. If a baseline period is specified, additional
data for baseline values and deviations are included. The output contains
the following columns / layers:

\itemize{
\item{\code{.linked}: Linked climate indicator value}
\item{\code{.baseline}: Linked baseline indicator value (if applicable)}
\item{\code{.deviation}: Difference between \code{.linked} and \code{.baseline} (if applicable)}
}
}
\description{
Augments spatio-temporal data with indicators from the
Copernicus earth observation database (ERA5).
The function performs the following pre-/post-processing steps:

\itemize{
\item{Construct time adjustments (time aggregations, time lags)}
\item{Compute space adjustments (spatial buffers)}
\item{Download monthly statistics from Copernicus database}
\item{Link raster statistics back to input}
\item{Optionally, add comparative statistics based on a baseline period}
}

This function interfaces the monthly means of ERA5 indicators. For daily
statistics see \code{\link{link_daily}}.
}
\details{
This function interacts with the Copernicus Climate Data Store (CDS) API to
download ERA5 monthly reanalysis data for a specified climate indicator and
time period. The input spatial points (an sf object) are first optionally
buffered (using the \code{buffer} argument) to expand the extraction area. The
function then determines the geographic extent from the (possibly buffered)
points and adjusts the time dimension based on the specified \code{date_var},
\code{time_lag}, and \code{time_span} (all in months). Monthly time sequences are
constructed assuming that dates correspond to the first day of each month.
The function downloads the corresponding monthly data (or hourly-based
monthly averages if \code{by_hour} is specified) and extracts these values for
each pointâ€”using a direct cell match when \code{buffer = 0} or aggregating over
the buffer area when \code{buffer > 0}. If a baseline period is provided (e.g.,
\code{baseline = c("1980", "2010")}), baseline monthly statistics are downloaded
for the specified period and appended as an additional attribute.
Optionally, deviations between the focal and baseline values may be
computed.

The following indicators are currently supported:

\tabular{ll}{
\strong{Land} \tab \strong{Single Levels}\cr
\code{2m_temperature}                  \tab \code{2m_temperature}                 \cr
\code{total_precipitation}             \tab \code{10m_u_component_of_wind}        \cr
\code{10m_u_component_of_wind}         \tab \code{10m_v_component_of_wind}        \cr
\code{10m_v_component_of_wind}         \tab \code{10m_wind_speed}                 \cr
\code{leaf_area_index_high_vegetation} \tab \code{total_cloud_cover}              \cr
\code{leaf_area_index_low_vegetation}  \tab \code{leaf_area_index_high_vegetation}\cr
\code{snowfall}                        \tab \code{leaf_area_index_low_vegetation}
}
}
\note{
Users must have a CDS account and have their API key configured for
\code{ecmwfr}.
}
\section{Parallel processing}{

This function can use parallel processing with chunking via
\code{\link[future.apply]{future_lapply}} when \code{parallel = TRUE}. If
\code{parallel = FALSE}, the function runs sequentially. When \code{parallel = TRUE},
set your parallel plan (for example, using
\code{\link[future]{plan}(multisession, workers = 6)})
before calling this function. If no plan is set before but \code{parallel = TRUE},
the function will run sequentially through the chunks, which will most
likely increase duration.
}

\examples{
\dontrun{
library(sf)

# Create sample point data (sf object)
pts <- data.frame(
  lon = c(13.4, 11.6, 9.9),
  lat = c(52.5, 51.3, 50.1),
  date = c("2014-08-01", "2014-08-01", "2014-08-01")
)
pts_sf <- st_as_sf(pts, coords = c("lon", "lat"), crs = 4326)

# Example 1: Direct extraction (buffer = 0)
result1 <- link_monthly(pts_sf, indicator = "2m_temperature")

# Example 2: Aggregated extraction with a 5 km buffer and a baseline period
result2 <- link_monthly(
  pts_sf,
  indicator = "2m_temperature",
  buffer = 5,
  baseline = c("1980", "2010")
)

# View the results:
head(result1)
head(result2)}

}
